{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn import metrics\n",
    "import scattertext as st\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Initial Spam Classification with NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# filename = 'sms_data'\n",
    "# sms_df = pd.read_csv(filename, header=None, sep='\t', names=['class_sms', 'sms'])\n",
    "# sms_df['sms'] = sms_df['sms'].str.replace(r'\\d+', '')\n",
    "\n",
    "# sms_df['sms'] = sms_df['sms'].apply(lambda x: x.split())\n",
    "# sms_df['sms'] = sms_df['sms'].apply(lambda x: [word for word in x if len(word) > 2])\n",
    "# sms_df['sms'] = sms_df['sms'].apply(lambda x: ', '.join(x))\n",
    "# # print(sms_df['sms'])\n",
    "\n",
    "# X = sms_df.sms\n",
    "# y = sms_df.class_sms\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "# vect = CountVectorizer()\n",
    "# X_train_dtm = vect.fit_transform(X_train) \n",
    "# # print(vect.get_feature_names())\n",
    "# X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "# nb = MultinomialNB()\n",
    "# nb.fit(X_train_dtm, y_train)\n",
    "# y_pred_class = nb.predict(X_test_dtm)  \n",
    "# false_positive = X_test[(y_test == 'spam') & (y_pred_class == 'ham')]\n",
    "# false_negative = X_test[(y_test == 'ham') & (y_pred_class == 'spam')]\n",
    "# # print(false_positive)\n",
    "# # print(false_negative)\n",
    "\n",
    "# # print(y_test.value_counts())  # examine the class distribution of the testing set (using a Pandas Series method)\n",
    "# # print(y_test.value_counts().head(1) / len(y_test)) \n",
    "# print('General Accuracy:', metrics.accuracy_score(y_test, y_pred_class)) # 0.9885\n",
    "# confusion_matrix = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "# false_positive_rate = confusion_matrix[1][0] / (confusion_matrix[1][0] + confusion_matrix[1][1])\n",
    "# print('False Positive Rate:', false_positive_rate*100) # 5.405% <-- terrible!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train_tokens = vect.get_feature_names()\n",
    "# ham_token_count = nb.feature_count_[0, :]\n",
    "# spam_token_count = nb.feature_count_[1, :]\n",
    "# tokens = pd.DataFrame({'token': X_train_tokens, 'ham': ham_token_count, 'spam': spam_token_count})\n",
    "# tokens['ham'] = tokens.ham + 1\n",
    "# tokens['spam'] = tokens.spam + 1\n",
    "# tokens['ham'] = tokens.ham / nb.class_count_[0]\n",
    "# tokens['spam'] = tokens.spam / nb.class_count_[1]\n",
    "# tokens['ham_ratio'] = tokens.ham / tokens.spam\n",
    "# tokens['spam_ratio'] = tokens.spam / tokens.ham\n",
    "# print(tokens.sort_values('ham_ratio', ascending=False).head(10))  # top 10 tokens predictive for 5-star\n",
    "# print(tokens.sort_values('spam_ratio', ascending=False).head(10))  # top 10 tokens predictive for 5-star\n",
    "# print(tokens.sort_values('one_star_ratio', ascending=False).head(10))  # top 10 tokens predictive for 1-star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## The 2 blocks of code below produce the HTML text visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nlp = st.WhitespaceNLP.whitespace_nlp\n",
    "# corpus = st.CorpusFromPandas(sms_df, \n",
    "#                               category_col='class_sms', \n",
    "#                               text_col='sms',\n",
    "#                               nlp=nlp).build()\n",
    "# term_freq_df = corpus.get_term_freq_df()\n",
    "# term_freq_df['spam'] = corpus.get_scaled_f_scores('spam')\n",
    "# pprint(list(term_freq_df.sort_values(by='spam', ascending=False).index[:10])) # words most associated with spam\n",
    "# term_freq_df['ham'] = corpus.get_scaled_f_scores('ham')\n",
    "# pprint(list(term_freq_df.sort_values(by='ham', ascending=False).index[:10]))  # words most associated with ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# html = st.produce_scattertext_explorer(corpus,\n",
    "#           category='spam',\n",
    "#           category_name='spam',\n",
    "#           not_category_name='ham',\n",
    "#           width_in_pixels=1000,\n",
    "#           )\n",
    "# open(\"Convention-Visualization.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Post-Naive Bayes:\n",
    "# Tokenization (playing around with data, reading RP/posts to get ideas )\n",
    "# Feature Selection (information gain)\n",
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Accuracy: 0.989949748744\n",
      "False Positive Rate: 5.40540540541\n",
      "           spam              token\n",
      "11749  0.274021               call\n",
      "1285   0.186833               Call\n",
      "2479   0.153025               FREE\n",
      "31944  0.126335                www\n",
      "21661  0.115658             mobile\n",
      "24396  0.113879              prize\n",
      "28684  0.112100               text\n",
      "12580  0.108541              claim\n",
      "8086   0.104982                Txt\n",
      "30005  0.094306                txt\n",
      "6625   0.088968               STOP\n",
      "25245  0.085409              reply\n",
      "16145  0.083630               free\n",
      "12152  0.080071               cash\n",
      "31075  0.078292               week\n",
      "27816  0.076512               stop\n",
      "13145  0.076512            contact\n",
      "26408  0.071174            service\n",
      "12812  0.069395                com\n",
      "5423   0.067616              Nokia\n",
      "24229  0.065836                ppm\n",
      "5272   0.064057                NOW\n",
      "16574  0.062278                get\n",
      "23551  0.060498                per\n",
      "6354   0.058719              Reply\n",
      "22468  0.058719                new\n",
      "13565  0.058719           customer\n",
      "21436  0.056940                min\n",
      "7562   0.056940               Text\n",
      "29587  0.056940               tone\n",
      "...         ...                ...\n",
      "12678  0.001779         close Frnd\n",
      "12675  0.001779        clocks back\n",
      "12700  0.001779    clover whatever\n",
      "12710  0.001779               clue\n",
      "12746  0.001779         coin becoz\n",
      "12711  0.001779       clue spanish\n",
      "12745  0.001779           coin air\n",
      "12744  0.001779               coin\n",
      "12743  0.001779         coimbatore\n",
      "12742  0.001779         coffee wif\n",
      "12741  0.001779         coffee run\n",
      "12740  0.001779       coffee await\n",
      "12739  0.001779             coffee\n",
      "12736  0.001779           code acc\n",
      "12733  0.001779               coco\n",
      "12732  0.001779  cocksuckers makes\n",
      "12731  0.001779        cocksuckers\n",
      "12729  0.001779         cock Where\n",
      "12727  0.001779         cochin pls\n",
      "12726  0.001779             cochin\n",
      "12725  0.001779    coccooning home\n",
      "12724  0.001779         coccooning\n",
      "12723  0.001779         coast Haiz\n",
      "12722  0.001779              coast\n",
      "12721  0.001779          coach hot\n",
      "12720  0.001779              coach\n",
      "12714  0.001779           cme want\n",
      "12713  0.001779           cme This\n",
      "12712  0.001779                cme\n",
      "32192  0.001779        ã€¨ud evening\n",
      "\n",
      "[32193 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "filename = 'sms_data'\n",
    "sms_df = pd.read_csv(filename, header=None, sep='\t', names=['class_sms', 'sms'])\n",
    "\n",
    "sms_df['sms'] = sms_df['sms'].str.replace(r'\\d+', '')\n",
    "sms_df['sms'] = sms_df['sms'].str.replace(r'\\W*\\b\\w{1,2}\\b', '') # regex for replacing words of len less then 2\n",
    "sms_df['sms'] = sms_df['sms'].str.replace(r'\\d+', '')\n",
    "# print(len(sms_df.loc[sms_df['class_sms'] == 'spam']))\n",
    "sms_df.loc[sms_df['class_sms'] == 'spam'].to_csv('spam_fi')\n",
    "\n",
    "X = sms_df.sms\n",
    "y = sms_df.class_sms\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "stopword = stopwords.words('english')\n",
    "stopword.append('You')\n",
    "stopword.append('Your')\n",
    "vect = CountVectorizer(token_pattern=u'(?u)\\\\b\\\\w+\\\\b', lowercase=False, ngram_range=(1,2), stop_words=stopword)\n",
    "\n",
    "X_train_dtm = vect.fit_transform(X_train) \n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)  \n",
    "print('General Accuracy:', metrics.accuracy_score(y_test, y_pred_class)) # 0.9885\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "false_positive_rate = confusion_matrix[1][0] / (confusion_matrix[1][0] + confusion_matrix[1][1])\n",
    "print('False Positive Rate:', false_positive_rate*100) # 5.405% <-- terrible!\n",
    "# print (classification_report(y_test, y_pred_class))\n",
    "spam_token_count = nb.feature_count_[1, :] \n",
    "X_train_tokens = vect.get_feature_names()\n",
    "tokens = pd.DataFrame({'token':X_train_tokens, 'spam':spam_token_count})\n",
    "tokens['spam'] = tokens.spam + 1\n",
    "tokens['spam'] = tokens.spam / nb.class_count_[1]\n",
    "print(tokens.sort_values('spam', ascending=False))\n",
    "false_positive = X_test[(y_test == 'spam') & (y_pred_class == 'ham')]\n",
    "false_negative = X_test[(y_test == 'ham') & (y_pred_class == 'spam')]\n",
    "# print(false_positive)\n",
    "# print(false_negative)\n",
    "        \n",
    "\n",
    "\n",
    "# vect = CountVectorizer(token_pattern=u'(?u)\\\\b\\\\w+\\\\b', lowercase=False, ngram_range=(1,2), tokenizer=TreebankWordTokenizer().tokenize)\n",
    "# print(vect.get_feature_names())\n",
    "# print(len(vect.get_feature_names()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nlp = st.WhitespaceNLP.whitespace_nlp\n",
    "# corpus = st.CorpusFromPandas(sms_df, \n",
    "#                               category_col='class_sms', \n",
    "#                               text_col='sms',\n",
    "#                               nlp=nlp).build()\n",
    "# term_freq_df = corpus.get_term_freq_df()\n",
    "# term_freq_df['spam'] = corpus.get_scaled_f_scores('spam')\n",
    "# pprint(list(term_freq_df.sort_values(by='spam', ascending=False).index[:10])) # words most associated with spam\n",
    "# term_freq_df['ham'] = corpus.get_scaled_f_scores('ham')\n",
    "# pprint(list(term_freq_df.sort_values(by='ham', ascending=False).index[:10]))  # words most associated with ham\n",
    "# html = st.produce_scattertext_explorer(corpus,\n",
    "#           category='spam',\n",
    "#           category_name='spam',\n",
    "#           not_category_name='ham',\n",
    "#           width_in_pixels=1000,\n",
    "#           )\n",
    "# open(\"Convention-Visualization.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
