{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn import metrics\n",
    "import scattertext as st\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Initial Spam Classification with NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# filename = 'sms_data'\n",
    "# sms_df = pd.read_csv(filename, header=None, sep='\t', names=['class_sms', 'sms'])\n",
    "# sms_df['sms'] = sms_df['sms'].str.replace(r'\\d+', '')\n",
    "\n",
    "# sms_df['sms'] = sms_df['sms'].apply(lambda x: x.split())\n",
    "# sms_df['sms'] = sms_df['sms'].apply(lambda x: [word for word in x if len(word) > 2])\n",
    "# sms_df['sms'] = sms_df['sms'].apply(lambda x: ', '.join(x))\n",
    "# # print(sms_df['sms'])\n",
    "\n",
    "# X = sms_df.sms\n",
    "# y = sms_df.class_sms\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "# vect = CountVectorizer()\n",
    "# X_train_dtm = vect.fit_transform(X_train) \n",
    "# # print(vect.get_feature_names())\n",
    "# X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "# nb = MultinomialNB()\n",
    "# nb.fit(X_train_dtm, y_train)\n",
    "# y_pred_class = nb.predict(X_test_dtm)  \n",
    "# false_positive = X_test[(y_test == 'spam') & (y_pred_class == 'ham')]\n",
    "# false_negative = X_test[(y_test == 'ham') & (y_pred_class == 'spam')]\n",
    "# # print(false_positive)\n",
    "# # print(false_negative)\n",
    "\n",
    "# # print(y_test.value_counts())  # examine the class distribution of the testing set (using a Pandas Series method)\n",
    "# # print(y_test.value_counts().head(1) / len(y_test)) \n",
    "# print('General Accuracy:', metrics.accuracy_score(y_test, y_pred_class)) # 0.9885\n",
    "# confusion_matrix = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "# false_positive_rate = confusion_matrix[1][0] / (confusion_matrix[1][0] + confusion_matrix[1][1])\n",
    "# print('False Positive Rate:', false_positive_rate*100) # 5.405% <-- terrible!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train_tokens = vect.get_feature_names()\n",
    "# ham_token_count = nb.feature_count_[0, :]\n",
    "# spam_token_count = nb.feature_count_[1, :]\n",
    "# tokens = pd.DataFrame({'token': X_train_tokens, 'ham': ham_token_count, 'spam': spam_token_count})\n",
    "# tokens['ham'] = tokens.ham + 1\n",
    "# tokens['spam'] = tokens.spam + 1\n",
    "# tokens['ham'] = tokens.ham / nb.class_count_[0]\n",
    "# tokens['spam'] = tokens.spam / nb.class_count_[1]\n",
    "# tokens['ham_ratio'] = tokens.ham / tokens.spam\n",
    "# tokens['spam_ratio'] = tokens.spam / tokens.ham\n",
    "# print(tokens.sort_values('ham_ratio', ascending=False).head(10))  # top 10 tokens predictive for 5-star\n",
    "# print(tokens.sort_values('spam_ratio', ascending=False).head(10))  # top 10 tokens predictive for 5-star\n",
    "# print(tokens.sort_values('one_star_ratio', ascending=False).head(10))  # top 10 tokens predictive for 1-star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## The 2 blocks of code below produce the HTML text visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nlp = st.WhitespaceNLP.whitespace_nlp\n",
    "# corpus = st.CorpusFromPandas(sms_df, \n",
    "#                               category_col='class_sms', \n",
    "#                               text_col='sms',\n",
    "#                               nlp=nlp).build()\n",
    "# term_freq_df = corpus.get_term_freq_df()\n",
    "# term_freq_df['spam'] = corpus.get_scaled_f_scores('spam')\n",
    "# pprint(list(term_freq_df.sort_values(by='spam', ascending=False).index[:10])) # words most associated with spam\n",
    "# term_freq_df['ham'] = corpus.get_scaled_f_scores('ham')\n",
    "# pprint(list(term_freq_df.sort_values(by='ham', ascending=False).index[:10]))  # words most associated with ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# html = st.produce_scattertext_explorer(corpus,\n",
    "#           category='spam',\n",
    "#           category_name='spam',\n",
    "#           not_category_name='ham',\n",
    "#           width_in_pixels=1000,\n",
    "#           )\n",
    "# open(\"Convention-Visualization.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Post-Naive Bayes:\n",
    "# Tokenization (playing around with data, reading RP/posts to get ideas )\n",
    "# Feature Selection (information gain)\n",
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to']\n",
      "General Accuracy: 0.990667623833\n",
      "False Positive Rate: 6.48648648649\n",
      "           spam          token\n",
      "871    0.279359              2\n",
      "16796  0.270463           call\n",
      "1511   0.192171              4\n",
      "3918   0.186833           Call\n",
      "30503  0.177936             on\n",
      "30040  0.172598            now\n",
      "21858  0.163701           from\n",
      "5232   0.153025           FREE\n",
      "12315  0.153025              U\n",
      "39795  0.144128             ur\n",
      "484    0.142349              1\n",
      "42113  0.126335            www\n",
      "28501  0.115658         mobile\n",
      "32466  0.113879          prize\n",
      "37569  0.112100           text\n",
      "17801  0.108541          claim\n",
      "12139  0.106762             To\n",
      "13826  0.106762            You\n",
      "12273  0.103203            Txt\n",
      "39185  0.097865              u\n",
      "13935  0.096085           Your\n",
      "11435  0.096085              T\n",
      "33865  0.096085              s\n",
      "30857  0.090747           only\n",
      "39114  0.088968            txt\n",
      "10709  0.088968           STOP\n",
      "24688  0.088968             in\n",
      "724    0.085409           150p\n",
      "33430  0.085409          reply\n",
      "21658  0.080071           free\n",
      "...         ...            ...\n",
      "17709  0.001779       chikku u\n",
      "17708  0.001779    chikku then\n",
      "17707  0.001779  chikku simple\n",
      "17706  0.001779      chikku nt\n",
      "17705  0.001779   chikku nange\n",
      "17704  0.001779      chikku il\n",
      "17703  0.001779     chikku gud\n",
      "17702  0.001779   chikku going\n",
      "17701  0.001779  chikku chikku\n",
      "17700  0.001779     chikku ali\n",
      "17699  0.001779      chikku DB\n",
      "17698  0.001779      chikku Bt\n",
      "17697  0.001779       chikku B\n",
      "17695  0.001779         chikku\n",
      "17676  0.001779    chess comes\n",
      "17692  0.001779      chief can\n",
      "17691  0.001779          chief\n",
      "17690  0.001779   chicken rice\n",
      "17689  0.001779  chicken curry\n",
      "17688  0.001779  chicken broth\n",
      "17687  0.001779        chicken\n",
      "17686  0.001779     chick huge\n",
      "17685  0.001779          chick\n",
      "17682  0.001779     chez jules\n",
      "17681  0.001779           chez\n",
      "17680  0.001779           chex\n",
      "17679  0.001779  chest abdomen\n",
      "17678  0.001779     chest Buzz\n",
      "17677  0.001779          chest\n",
      "42535  0.001779          鈥 〨ud\n",
      "\n",
      "[42536 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "filename = 'sms_data'\n",
    "sms_df = pd.read_csv(filename, header=None, sep='\t', names=['class_sms', 'sms'])\n",
    "X = sms_df.sms\n",
    "y = sms_df.class_sms\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "stopword = stopwords.words('english')[0:80]\n",
    "print(stopword)\n",
    "vect = CountVectorizer(token_pattern=u'(?u)\\\\b\\\\w+\\\\b', lowercase=False, ngram_range=(1,2), stop_words=stopword)\n",
    "X_train_dtm = vect.fit_transform(X_train) \n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)  \n",
    "print('General Accuracy:', metrics.accuracy_score(y_test, y_pred_class)) # 0.9885\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "false_positive_rate = confusion_matrix[1][0] / (confusion_matrix[1][0] + confusion_matrix[1][1])\n",
    "print('False Positive Rate:', false_positive_rate*100) # 5.405% <-- terrible!\n",
    "# print (classification_report(y_test, y_pred_class))\n",
    "spam_token_count = nb.feature_count_[1, :] \n",
    "X_train_tokens = vect.get_feature_names()\n",
    "tokens = pd.DataFrame({'token':X_train_tokens, 'spam':spam_token_count})\n",
    "tokens['spam'] = tokens.spam + 1\n",
    "tokens['spam'] = tokens.spam / nb.class_count_[1]\n",
    "print(tokens.sort_values('spam', ascending=False))\n",
    "        \n",
    "\n",
    "\n",
    "# vect = CountVectorizer(token_pattern=u'(?u)\\\\b\\\\w+\\\\b', lowercase=False, ngram_range=(1,2), tokenizer=TreebankWordTokenizer().tokenize)\n",
    "# print(vect.get_feature_names())\n",
    "# print(len(vect.get_feature_names()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nlp = st.WhitespaceNLP.whitespace_nlp\n",
    "# corpus = st.CorpusFromPandas(sms_df, \n",
    "#                               category_col='class_sms', \n",
    "#                               text_col='sms',\n",
    "#                               nlp=nlp).build()\n",
    "# term_freq_df = corpus.get_term_freq_df()\n",
    "# term_freq_df['spam'] = corpus.get_scaled_f_scores('spam')\n",
    "# pprint(list(term_freq_df.sort_values(by='spam', ascending=False).index[:10])) # words most associated with spam\n",
    "# term_freq_df['ham'] = corpus.get_scaled_f_scores('ham')\n",
    "# pprint(list(term_freq_df.sort_values(by='ham', ascending=False).index[:10]))  # words most associated with ham\n",
    "# html = st.produce_scattertext_explorer(corpus,\n",
    "#           category='spam',\n",
    "#           category_name='spam',\n",
    "#           not_category_name='ham',\n",
    "#           width_in_pixels=1000,\n",
    "#           )\n",
    "# open(\"Convention-Visualization.html\", 'wb').write(html.encode('utf-8'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
