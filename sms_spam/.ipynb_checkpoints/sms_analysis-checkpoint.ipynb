{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import scattertext as st\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2295               You, have, new, message., Please, call\n",
      "5110               You, have, new, message., Please, call\n",
      "3530    Xmas, New, Years, Eve, tickets, are, now, sale...\n",
      "684     I'm, sue., years, old, and, work, lapdancer., ...\n",
      "1893    CALL, LISTEN, EXTREME, DIRTY, LIVE, CHAT, GOIN...\n",
      "2941               You, have, new, message., Please, call\n",
      "2821    INTERFLORA, Â“It's, not, too, late, order, Inte...\n",
      "2247    babe, goten, bout, me?', scammers, getting, sm...\n",
      "4514          Money, have, won, wining, number, wot, next\n",
      "Name: sms, dtype: object\n",
      "4419                          When, you, get, free,, call\n",
      "1587    There, are, other, charges, after, transfer, c...\n",
      "2903    Bill,, in:, Are, there, any, letters, for, me....\n",
      "45                         calls..messages..missed, calls\n",
      "3589    you, were/are, free, can, give., Otherwise, na...\n",
      "2162    she, replying., Has, boye, changed, his, phone...\n",
      "3415                               pic., Please, re-send.\n",
      "1988                       calls..messages..missed, calls\n",
      "Name: sms, dtype: object\n",
      "0.987796123475\n",
      "[[1200    8]\n",
      " [   9  176]]\n"
     ]
    }
   ],
   "source": [
    "filename = 'sms_data'\n",
    "sms_df = pd.read_csv(filename, header=None, sep='\t', names=['class_sms', 'sms'])\n",
    "sms_df['sms'] = sms_df['sms'].str.replace('\\d+', '')\n",
    "sms_df['sms'] = sms_df['sms'].apply(lambda x: x.split())\n",
    "sms_df['sms'] = sms_df['sms'].apply(lambda x: [word for word in x if len(word) > 2])\n",
    "sms_df['sms'] = sms_df['sms'].apply(lambda x: ', '.join(x))\n",
    "# print(sms_df['sms'])\n",
    "\n",
    "X = sms_df.sms\n",
    "y = sms_df.class_sms\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "vect = CountVectorizer(stop_words='english')\n",
    "X_train_dtm = vect.fit_transform(X_train) \n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)  \n",
    "false_positive = X_test[(y_test == 'spam') & (y_pred_class == 'ham')]\n",
    "false_negative = X_test[(y_test == 'ham') & (y_pred_class == 'spam')]\n",
    "print(false_positive)\n",
    "print(false_negative)\n",
    "\n",
    "\n",
    "# print(y_test.value_counts())  # examine the class distribution of the testing set (using a Pandas Series method)\n",
    "# print(y_test.value_counts().head(1) / len(y_test)) \n",
    "print(metrics.accuracy_score(y_test, y_pred_class)) \n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ham      spam  token  ham_ratio  spam_ratio\n",
      "2272  0.063865  0.001779     gt  35.892176    0.027861\n",
      "3176  0.063865  0.001779     lt  35.892176    0.027861\n",
      "3133  0.032900  0.001779    lor  18.489909    0.054084\n",
      "2960  0.030688  0.001779  later  17.246890    0.057981\n",
      "3761  0.027647  0.001779     ok  15.537738    0.064359\n",
      "1035  0.048936  0.003559   come  13.750899    0.072723\n",
      "6041  0.019630  0.001779    way  11.031794    0.090647\n",
      "309   0.019630  0.001779    ask  11.031794    0.090647\n",
      "1496  0.019077  0.001779  doing  10.721040    0.093275\n",
      "6303  0.017694  0.001779   yeah   9.944153    0.100562\n",
      "           ham      spam       token  ham_ratio  spam_ratio\n",
      "963   0.000276  0.158363       claim   0.001746  572.798932\n",
      "4221  0.000276  0.135231       prize   0.002044  489.131673\n",
      "5772  0.000276  0.090747          uk   0.003047  328.233096\n",
      "5635  0.000276  0.085409        tone   0.003237  308.925267\n",
      "2277  0.000276  0.076512  guaranteed   0.003613  276.745552\n",
      "4152  0.000276  0.069395         ppm   0.003984  251.001779\n",
      "6265  0.000553  0.129893         www   0.004257  234.911922\n",
      "1211  0.000276  0.055160          cs   0.005012  199.514235\n",
      "377   0.000276  0.053381     awarded   0.005179  193.078292\n",
      "4565  0.000276  0.044484    ringtone   0.006215  160.898577\n"
     ]
    }
   ],
   "source": [
    "X_train_tokens = vect.get_feature_names()\n",
    "ham_token_count = nb.feature_count_[0, :]\n",
    "spam_token_count = nb.feature_count_[1, :]\n",
    "tokens = pd.DataFrame({'token': X_train_tokens, 'ham': ham_token_count, 'spam': spam_token_count})\n",
    "tokens['ham'] = tokens.ham + 1\n",
    "tokens['spam'] = tokens.spam + 1\n",
    "tokens['ham'] = tokens.ham / nb.class_count_[0]\n",
    "tokens['spam'] = tokens.spam / nb.class_count_[1]\n",
    "tokens['ham_ratio'] = tokens.ham / tokens.spam\n",
    "tokens['spam_ratio'] = tokens.spam / tokens.ham\n",
    "print(tokens.sort_values('ham_ratio', ascending=False).head(10))  # top 10 tokens predictive for 5-star\n",
    "print(tokens.sort_values('spam_ratio', ascending=False).head(10))  # top 10 tokens predictive for 5-star\n",
    "# print(tokens.sort_values('one_star_ratio', ascending=False).head(10))  # top 10 tokens predictive for 1-star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['prize',\n",
      " 'have won',\n",
      " 'your mobile',\n",
      " 'claim',\n",
      " 'tone',\n",
      " 'guaranteed',\n",
      " 'ppm',\n",
      " 'awarded',\n",
      " 'co uk',\n",
      " 'uk']\n",
      "['lt', 'she', 'i ll', 'lor', 'gt', 'lt gt', 'later', 'ask', 'said', 'doing']\n"
     ]
    }
   ],
   "source": [
    "nlp = st.WhitespaceNLP.whitespace_nlp\n",
    "corpus = st.CorpusFromPandas(sms_df, \n",
    "                              category_col='class_sms', \n",
    "                              text_col='sms',\n",
    "                              nlp=nlp).build()\n",
    "term_freq_df = corpus.get_term_freq_df()\n",
    "term_freq_df['spam'] = corpus.get_scaled_f_scores('spam')\n",
    "pprint(list(term_freq_df.sort_values(by='spam', ascending=False).index[:10])) # words most associated with spam\n",
    "term_freq_df['ham'] = corpus.get_scaled_f_scores('ham')\n",
    "pprint(list(term_freq_df.sort_values(by='ham', ascending=False).index[:10]))  # words most associated with ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2792ced01c1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mnot_category_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ham'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mwidth_in_pixels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           metadata=sms_df.sms)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Convention-Visualization.html\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Rahul/anaconda/lib/python3.5/site-packages/scattertext/__init__.py\u001b[0m in \u001b[0;36mproduce_scattertext_explorer\u001b[0;34m(corpus, category, category_name, not_category_name, protocol, pmi_threshold_coefficient, minimum_term_frequency, minimum_not_category_term_frequency, max_terms, filter_unigrams, height_in_pixels, width_in_pixels, max_snippets, max_docs_per_category, metadata, scores, x_coords, y_coords, singleScoreMode, sort_by_dist, reverse_sort_scores_for_not_category, use_full_doc, transform, jitter, grey_zero_scores, term_ranker, asian_mode, use_non_text_features, show_characteristic, word_vec_use_p_vals, max_p_val, p_value_colors, term_significance, save_svg_button, x_label, y_label, d3_url, d3_scale_chromatic_url, pmi_filter_thresold, alternative_text_field)\u001b[0m\n\u001b[1;32m    276\u001b[0m                                                             \u001b[0mmax_docs_per_category\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_docs_per_category\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                                                             \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m \t                                                    alternative_text_field=alternative_text_field)\n\u001b[0m\u001b[1;32m    279\u001b[0m \treturn HTMLVisualizationAssembly(VizDataAdapter(scatter_chart_data),\n\u001b[1;32m    280\u001b[0m                                          \u001b[0mwidth_in_pixels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth_in_pixels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Rahul/anaconda/lib/python3.5/site-packages/scattertext/ScatterChartExplorer.py\u001b[0m in \u001b[0;36mto_dict\u001b[0;34m(self, category, category_name, not_category_name, scores, metadata, max_docs_per_category, transform, alternative_text_field)\u001b[0m\n\u001b[1;32m     71\u001b[0m \t\t                         transform=transform)\n\u001b[1;32m     72\u001b[0m                 \u001b[0mdocs_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_docs_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_docs_per_category\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malternative_text_field\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'docs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_docs_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs_getter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Rahul/anaconda/lib/python3.5/site-packages/scattertext/ScatterChartExplorer.py\u001b[0m in \u001b[0;36m_get_docs_structure\u001b[0;34m(self, docs_getter, metadata)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_get_docs_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs_getter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                         \u001b[0;32mreturn\u001b[0m \u001b[0mdocs_getter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels_and_texts_and_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mdocs_getter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels_and_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Rahul/anaconda/lib/python3.5/site-packages/scattertext/DocsAndLabelsFromCorpus.py\u001b[0m in \u001b[0;36mget_labels_and_texts_and_meta\u001b[0;34m(self, metadata)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;31m# type: (np.array) -> dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels_and_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meta'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "html = st.produce_scattertext_explorer(corpus,\n",
    "          category='spam',\n",
    "          category_name='spam',\n",
    "          not_category_name='ham',\n",
    "          width_in_pixels=1000,\n",
    "          )\n",
    "open(\"Convention-Visualization.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
