{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn import metrics\n",
    "import scattertext as st\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Initial Spam Classification with NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Accuracy: 0.988513998564\n",
      "False Positive Rate: 5.40540540541\n"
     ]
    }
   ],
   "source": [
    "filename = 'sms_data'\n",
    "sms_df = pd.read_csv(filename, header=None, sep='\t', names=['class_sms', 'sms'])\n",
    "sms_df['sms'] = sms_df['sms'].str.replace(r'\\d+', '')\n",
    "\n",
    "sms_df['sms'] = sms_df['sms'].apply(lambda x: x.split())\n",
    "sms_df['sms'] = sms_df['sms'].apply(lambda x: [word for word in x if len(word) > 2])\n",
    "sms_df['sms'] = sms_df['sms'].apply(lambda x: ', '.join(x))\n",
    "# print(sms_df['sms'])\n",
    "\n",
    "X = sms_df.sms\n",
    "y = sms_df.class_sms\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "vect = CountVectorizer()\n",
    "X_train_dtm = vect.fit_transform(X_train) \n",
    "# print(vect.get_feature_names())\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)  \n",
    "false_positive = X_test[(y_test == 'spam') & (y_pred_class == 'ham')]\n",
    "false_negative = X_test[(y_test == 'ham') & (y_pred_class == 'spam')]\n",
    "# print(false_positive)\n",
    "# print(false_negative)\n",
    "\n",
    "# print(y_test.value_counts())  # examine the class distribution of the testing set (using a Pandas Series method)\n",
    "# print(y_test.value_counts().head(1) / len(y_test)) \n",
    "print('General Accuracy:', metrics.accuracy_score(y_test, y_pred_class)) # 0.9885\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "false_positive_rate = confusion_matrix[1][0] / (confusion_matrix[1][0] + confusion_matrix[1][1])\n",
    "print('False Positive Rate:', false_positive_rate*100) # 5.405% <-- terrible!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train_tokens = vect.get_feature_names()\n",
    "# ham_token_count = nb.feature_count_[0, :]\n",
    "# spam_token_count = nb.feature_count_[1, :]\n",
    "# tokens = pd.DataFrame({'token': X_train_tokens, 'ham': ham_token_count, 'spam': spam_token_count})\n",
    "# tokens['ham'] = tokens.ham + 1\n",
    "# tokens['spam'] = tokens.spam + 1\n",
    "# tokens['ham'] = tokens.ham / nb.class_count_[0]\n",
    "# tokens['spam'] = tokens.spam / nb.class_count_[1]\n",
    "# tokens['ham_ratio'] = tokens.ham / tokens.spam\n",
    "# tokens['spam_ratio'] = tokens.spam / tokens.ham\n",
    "# print(tokens.sort_values('ham_ratio', ascending=False).head(10))  # top 10 tokens predictive for 5-star\n",
    "# print(tokens.sort_values('spam_ratio', ascending=False).head(10))  # top 10 tokens predictive for 5-star\n",
    "# print(tokens.sort_values('one_star_ratio', ascending=False).head(10))  # top 10 tokens predictive for 1-star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## The 2 blocks of code below produce the HTML text visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nlp = st.WhitespaceNLP.whitespace_nlp\n",
    "# corpus = st.CorpusFromPandas(sms_df, \n",
    "#                               category_col='class_sms', \n",
    "#                               text_col='sms',\n",
    "#                               nlp=nlp).build()\n",
    "# term_freq_df = corpus.get_term_freq_df()\n",
    "# term_freq_df['spam'] = corpus.get_scaled_f_scores('spam')\n",
    "# pprint(list(term_freq_df.sort_values(by='spam', ascending=False).index[:10])) # words most associated with spam\n",
    "# term_freq_df['ham'] = corpus.get_scaled_f_scores('ham')\n",
    "# pprint(list(term_freq_df.sort_values(by='ham', ascending=False).index[:10]))  # words most associated with ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# html = st.produce_scattertext_explorer(corpus,\n",
    "#           category='spam',\n",
    "#           category_name='spam',\n",
    "#           not_category_name='ham',\n",
    "#           width_in_pixels=1000,\n",
    "#           )\n",
    "# open(\"Convention-Visualization.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Post-Naive Bayes:\n",
    "# Tokenization (playing around with data, reading RP/posts to get ideas )\n",
    "# Feature Selection (information gain)\n",
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = 'sms_data'\n",
    "sms_df = pd.read_csv(filename, header=None, sep='\t', names=['class_sms', 'sms'])\n",
    "sms_df['sms'] = sms_df['sms'].str.replace(r'\\d+', '')t\n",
    "# sms_df['sms'] = sms_df['sms'].str.replace(r'/[>.<!@#$%^&*]/g', '')\n",
    "# sms_df['sms'] = sms_df['sms'].str.replace(';', ',')\n",
    "# sms_df['sms'] = sms_df['sms'].str.replace('&', '')\n",
    "# sms_df['sms'] = sms_df['sms'].str.replace('#', '')\n",
    "# sms_df['sms'] = sms_df['sms'].str.replace(':', '')\n",
    "# sms_df['sms'] = sms_df['sms'].str.replace(':', '')\n",
    "# sms_df['sms'] = sms_df['sms'].str.replace('(', '')\n",
    "# sms_df['sms'] = sms_df['sms'].str.replace(')', '')\n",
    "# sms_df['sms'] = sms_df['sms'].str.replace('()', '')\n",
    "# sms_df['sms'] = sms_df['sms'].str.replace('\\', '')\n",
    "# sms_df['sms'] = sms_df['sms'].str.replace('', '')\n",
    "sms_df['sms'] = sms_df['sms'].apply(lambda x: x.split())\n",
    "sms_df['sms'] = sms_df['sms'].apply(lambda x: [word for word in x if len(word) > 2])\n",
    "sms_df['sms'] = sms_df['sms'].apply(lambda x: ', '.join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def vocabSet(data):\n",
    "#     new_set = set([])\n",
    "#     for w in data:\n",
    "#         new_set = new_set | set(w)\n",
    "#     return list(new_set)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "# X_train_new = X_train.apply(lambda x: x.split(', '))\n",
    "# vocab = vocabSet(X_train_new)\n",
    "# # print(vocab)\n",
    "# vect = CountVectorizer(vocabulary=vocab)\n",
    "# X_train_dtm = vect.fit_transform(X_train) \n",
    "# X_test_dtm = vect.transform(X_test)\n",
    "# nb = MultinomialNB()\n",
    "# nb.fit(X_train_dtm, y_train)\n",
    "# y_pred_class = nb.predict(X_test_dtm)  \n",
    "# # print(metrics.accuracy_score(y_test, y_pred_class)) \n",
    "# confusion_matrix = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "# # print(confusion_matrix)\n",
    "# false_positive_rate = confusion_matrix[1][0] / (confusion_matrix[1][0] + confusion_matrix[1][1])\n",
    "# # print(false_positive_rate*100) \n",
    "# false_positive = X_test[(y_test == 'spam') & (y_pred_class == 'ham')]\n",
    "# false_negative = X_test[(y_test == 'ham') & (y_pred_class == 'spam')]\n",
    "# print(false_positive)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
